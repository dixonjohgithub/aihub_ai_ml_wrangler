# AI Hub AI/ML Wrangler

> A sophisticated statistical data imputation and analysis tool with AI-powered recommendations for feature engineering, encoding, and imputation strategies.

## ğŸš€ Overview

AI Hub AI/ML Wrangler is a web-based application designed for data scientists and research scientists to handle missing data in large datasets intelligently. The system leverages OpenAI's API to provide context-aware suggestions and automates complex statistical operations through an intuitive interface that mirrors the familiar AI Hub Data Wrangler design.

## âœ¨ Key Features

- **ğŸ¤– AI-Powered Analysis**: Utilizes OpenAI API for intelligent dataset assessment and recommendations
- **ğŸ“Š Comprehensive Imputation**: Supports statistical, ML-based, correlation-based, and time-series methods
- **ğŸ“ˆ Correlation Analysis**: Generates publication-ready correlation matrices with visualization
- **ğŸ“ Detailed Reporting**: Produces comprehensive markdown reports with full transformation audit trails
- **âš¡ Large Dataset Support**: Efficiently handles datasets >100MB with >1M rows
- **ğŸ”„ Interactive Configuration**: Real-time preview and comparison of imputation strategies
- **ğŸ¨ Familiar UI**: Consistent design with AI Hub Data Wrangler for seamless user experience

## ğŸ› ï¸ Technology Stack

### Frontend
- React 18 with TypeScript
- Vite build tool
- Tailwind CSS
- Recharts & Plotly.js for visualizations
- Axios for API communication

### Backend
- FastAPI (Python 3.10+)
- Pandas, NumPy, Scikit-learn
- Celery with Redis for task queuing
- PostgreSQL database
- Docker containerization

## ğŸ“‹ Prerequisites

- Node.js >= 18.0.0
- Python >= 3.10
- Docker and Docker Compose
- PostgreSQL 15
- Redis 7

## ğŸš€ Quick Start

### Development Setup

1. **Clone the repository**
```bash
git clone https://github.com/[username]/aihub_ai_ml_wrangler.git
cd aihub_ai_ml_wrangler
```

2. **Install dependencies**
```bash
# Install npm packages
npm install

# Set up Python virtual environment
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
cd ..
```

3. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env with your configuration (OpenAI API key, database credentials, etc.)
```

4. **Start with Docker Compose**
```bash
docker-compose -f docker-compose.dev.yml up
```

5. **Access the application**
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Documentation: http://localhost:8000/docs

### Manual Development (without Docker)

**Backend:**
```bash
cd backend
uvicorn app.main:app --reload --port 8000
```

**Frontend:**
```bash
cd frontend
npm run dev
```

## ğŸ“ Project Structure

```
aihub_ai_ml_wrangler/
â”œâ”€â”€ frontend/                # React TypeScript application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/         # Page components
â”‚   â”‚   â”œâ”€â”€ services/      # API service layer
â”‚   â”‚   â””â”€â”€ stores/        # State management
â”œâ”€â”€ backend/                # FastAPI Python application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/           # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/      # Business logic
â”‚   â”‚   â”œâ”€â”€ ml_modules/    # ML implementations
â”‚   â”‚   â””â”€â”€ models/        # Database models
â”œâ”€â”€ docker/                 # Docker configurations
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ sample_data/           # Sample datasets for testing
```

## ğŸ”„ Workflow

1. **Import**: Upload Data Wrangler export files (CSV, JSON)
2. **Analyze**: AI-powered analysis of missing data patterns
3. **Configure**: Select imputation strategies with AI recommendations
4. **Preview**: Real-time preview of imputation results
5. **Apply**: Process data with selected strategies
6. **Export**: Download imputed data, correlation matrices, and reports

## ğŸ“Š Output Files

- `[filename]_imputed.csv` - Complete dataset with imputed values
- `[filename]_correlation.csv` - Correlation matrix in standard format
- `[filename]_ml_report.md` - Comprehensive analysis report
- `[filename]_ml_metadata.json` - Complete transformation audit trail

## ğŸ§ª Testing

```bash
# Run all tests
npm test

# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test

# E2E tests
npm run test:e2e
```

## ğŸ“š Documentation

- [User Guide](docs/user-guide.md)
- [API Reference](docs/api-reference.md)
- [Development Guide](docs/development.md)
- [Deployment Guide](docs/deployment.md)

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”— Related Projects

- [AI Hub Data Wrangler](https://github.com/dixonjohgithub/aihub_data_wrangler) - Data preparation and transformation tool
- [Research Pipeline](https://dev.hsrn.nyu.edu/ai-hub/research_pipeline) - Core ML modules

## ğŸ“§ Support

For issues and questions:
- Create an issue on [GitHub Issues](https://github.com/[username]/aihub_ai_ml_wrangler/issues)
- Contact the AI Hub team at support@aihub.example.com

## ğŸ™ Acknowledgments

- OpenAI for API integration
- The AI Hub Data Wrangler team for UI/UX patterns
- The Research Pipeline team for ML modules

---

Built with â¤ï¸ by the AI Hub Team